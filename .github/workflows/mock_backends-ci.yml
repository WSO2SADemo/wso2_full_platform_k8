name: Integration - Mock Backends

on:
  push:
    paths:
      - 'apim-integration-artefacts-for-cicd-pipeline/integration/integrations-2/mock_backends/**'
      - '.github/workflows/mock_backends-ci.yml'
    branches:
      - main
  
  # Allows manual triggering
  workflow_dispatch:

jobs:
  build-and-deploy:
    runs-on: self-hosted

    env:
      BALLERINA_NAMESPACE: ballerina 
      PROJECT_DIR: apim-integration-artefacts-for-cicd-pipeline/integration/integrations-2/mock_backends
      IMAGE_TAG: "1.0.14"
      MOESIF_APP_ID: "eyJhcHAiOiI0OTM6MzM3MiIsInZlciI6IjIuMSIsIm9yZyI6Ijg2OjcxMiIsImlhdCI6MTc2NzIyNTYwMH0.XD0ilo6xwD8igZvVaQgz4w9kIvyx_yMTBbrBWdZyEVs" 

    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Print Ballerina Version
        run: bal version

      - name: Build Ballerina Project
        working-directory: ${{ env.PROJECT_DIR }}
        run: bal build
      
      - name: üîê Docker Login
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
          
      - name: Retag and Push Docker Image
        run: |
          # 1. Find the image ID built by Ballerina (uses the most recent one)
          BUILT_IMAGE=$(docker images --format "{{.Repository}}:{{.Tag}}" | grep "ramilu90/mock_backend" | head -n 1)
          
          if [ -z "$BUILT_IMAGE" ]; then
            echo "Error: No image found matching 'ramilu90/mock_backend'"
            exit 1
          fi
          
          echo "Found built image: $BUILT_IMAGE"
          
          # 2. Retag explicitly to match your deployment requirements
          TARGET_IMAGE="ramilu90/mock_backend:${{ env.IMAGE_TAG }}"
          docker tag "$BUILT_IMAGE" "$TARGET_IMAGE"
          
          # 3. Push
          docker push "$TARGET_IMAGE"

      - name: Ensure Namespace Exists
        run: kubectl create namespace ${{ env.BALLERINA_NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -

      # -----------------------------------------------------------
      # ‚úÖ FIX 1: ConfigMap with CORRECT formatting (using | )
      # -----------------------------------------------------------
      - name: Create ConfigMap
        run: |
          NAMESPACE="${{ env.BALLERINA_NAMESPACE }}"
          
          # We use cat <<EOF to handle newlines correctly. 
          cat <<EOF > configmap.yaml
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: ballerina-values-mock-backends
            namespace: $NAMESPACE
          data:
            BAL_CONFIG_DATA: |
              # [ballerinax.wso2.controlplane.dashboard]
              # url="https://cloud-icp.icp.svc.cluster.local:9743/dashboard/api"
              # heartbeatInterval=10
              # groupId="cluster1"
              # mgtApiUrl="https://mock-backends.ballerina.svc.cluster.local:9264/management/"
              # nodeId="mock_backends"

              [ballerina.observe]
              tracingEnabled=true
              tracingProvider="moesif"
              metricsEnabled=true
              metricsReporter="moesif"

              [ballerinax.moesif]
              applicationId = "eyJhcHAiOiI0OTM6MzM3MiIsInZlciI6IjIuMSIsIm9yZyI6Ijg2OjcxMiIsImlhdCI6MTc2NzIyNTYwMH0.XD0ilo6xwD8igZvVaQgz4w9kIvyx_yMTBbrBWdZyEVs"
              reporterBaseUrl = "https://api.moesif.net"   
              tracingReporterFlushInterval = 1000         
              tracingReporterBufferSize = 10000            
              isTraceLoggingEnabled = true                
              isPayloadLoggingEnabled = false 
              
              # # --- Logging to File (For FluentBit) ---
              # [ballerina.log]
              # format = "json"
              # [[ballerina.log.destinations]]
              # path = "/home/ballerina/logs/app.log"

              # [[ballerina.log.destinations]]
              # path = "/home/ballerina/logs/app.log"

              [ballerinax.wso2.apim.catalog]
              serviceUrl="https://acp-wso2am-acp-service.apim-cp.svc.cluster.local:9443/api/am/service-catalog/v1"
              tokenUrl="https://acp-wso2am-acp-service.apim-cp.svc.cluster.local:9443/oauth2/token"
              username="admin"
              password="admin"
              clientId="Pvn5k2ijIq04b1JzbPaSFJbyIfIa"
              clientSecret="y7gXcCrf9HJrBWTR5F0MbH6qpzQa"
          EOF

          echo "Applying Corrected ConfigMap..."
          kubectl apply -f configmap.yaml

      - name: Deploy Kubernetes Resources
        run: |
          K8S_DIR="${{ env.PROJECT_DIR }}/target/kubernetes/mock_backends"
          echo "Applying resources to Local Cluster..."
          kubectl apply -f ${K8S_DIR} -n ${{ env.BALLERINA_NAMESPACE }}

      # -----------------------------------------------------------
      # ‚úÖ FIX 2: Robust Service Patching (Handles Unnamed Ports)
      # -----------------------------------------------------------
      - name: Ensure Service & Patch Ports (Mock Backends)
        run: |
          NAMESPACE="${{ env.BALLERINA_NAMESPACE }}"
          DEPLOYMENT="mock-backends-deployment"
          SERVICE_NAME="mock-backends" 
          
          # Define Port Names
          PORT_9092_NAME="${SERVICE_NAME}-serviceport"
          PORT_9091_NAME="${SERVICE_NAME}-9091"
          PORT_9264_NAME="${SERVICE_NAME}-management"

          # ------------------------------------------------------------------
          # 1. Create Service if missing (Defaulting to 9092 as primary)
          # ------------------------------------------------------------------
          if ! kubectl get svc $SERVICE_NAME -n $NAMESPACE > /dev/null 2>&1; then
             echo "Service not found. Creating it now..."
             # We create it with port 9092 initially
             kubectl expose deployment $DEPLOYMENT -n $NAMESPACE --name=$SERVICE_NAME --port=9092 --target-port=9092 --type=ClusterIP
          else
             echo "Service $SERVICE_NAME already exists."
          fi

          # ------------------------------------------------------------------
          # 2. PATCH: Ensure Port 9092 exists and is named
          # ------------------------------------------------------------------
          # Check if 9092 exists
          if kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.ports[*].port}' | grep -q "\b9092\b"; then
             # Find which index corresponds to 9092
             INDEX_9092=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.ports[*]}' | jq -r '.[] | select(.port==9092) | .name')
             
             # Note: Retrieving the exact index in bash with kubectl jsonpath is tricky.
             # Easier Strategy: If we know it exists, we try to patch by name OR assume index 0 if it was just created.
             # However, for robustness, we will fetch the current name associated with port 9092 specifically.
             
             # Simple patch approach: Loop through ports to find the one with port=9092 and patch it?
             # Kubernetes 'strategic merge patch' uses 'port' as the merge key, so we can just patch by value.
             
             kubectl patch svc $SERVICE_NAME -n $NAMESPACE --type='strategic' -p='{"spec":{"ports":[{"port":9092,"name":"'"$PORT_9092_NAME"'"}]}}'
             echo "Patched/Verified Port 9092 name."
          else
             echo "Port 9092 missing. Adding it..."
             kubectl patch svc $SERVICE_NAME -n $NAMESPACE --type='json' -p='[{"op": "add", "path": "/spec/ports/-", "value": {"name": "'"$PORT_9092_NAME"'", "port": 9092, "targetPort": 9092, "protocol": "TCP"}}]'
          fi

          # ------------------------------------------------------------------
          # 3. PATCH: Ensure Port 9091 exists and is named
          # ------------------------------------------------------------------
          if kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.ports[*].port}' | grep -q "\b9091\b"; then
             echo "Port 9091 exists. Ensuring name is '$PORT_9091_NAME'..."
             # Strategic merge patch will update the name if the port matches
             kubectl patch svc $SERVICE_NAME -n $NAMESPACE --type='strategic' -p='{"spec":{"ports":[{"port":9091,"name":"'"$PORT_9091_NAME"'"}]}}'
          else
             echo "Port 9091 missing. Adding it..."
             kubectl patch svc $SERVICE_NAME -n $NAMESPACE --type='json' -p='[{"op": "add", "path": "/spec/ports/-", "value": {"name": "'"$PORT_9091_NAME"'", "port": 9091, "targetPort": 9091, "protocol": "TCP"}}]'
          fi

          # ------------------------------------------------------------------
          # 4. PATCH: Ensure Management Port (9264) exists and is named
          # ------------------------------------------------------------------
          if kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.ports[*].port}' | grep -q "\b9264\b"; then
             echo "Port 9264 exists. Ensuring name is '$PORT_9264_NAME'..."
             kubectl patch svc $SERVICE_NAME -n $NAMESPACE --type='strategic' -p='{"spec":{"ports":[{"port":9264,"name":"'"$PORT_9264_NAME"'"}]}}'
          else
             echo "Management port missing. Adding '$PORT_9264_NAME'..."
             kubectl patch svc $SERVICE_NAME -n $NAMESPACE --type='json' -p='[{"op": "add", "path": "/spec/ports/-", "value": {"name": "'"$PORT_9264_NAME"'", "port": 9264, "targetPort": 9264, "protocol": "TCP"}}]'
          fi

      - name: Patch Deployment (Volume Mounts & Env)
        run: |
          NAMESPACE="${{ env.BALLERINA_NAMESPACE }}"
          DEPLOYMENT="mock-backends-deployment"
          
          # Note: We do NOT wait for rollout here because if the pod is crashing, 
          # the rollout hangs and fails. We patch immediately to fix the crash.
          
          CONTAINER_NAME=$(kubectl get deployment $DEPLOYMENT -n $NAMESPACE -o jsonpath='{.spec.template.spec.containers[0].name}')
          
          echo "Patching Deployment $DEPLOYMENT (Container: $CONTAINER_NAME)..."
          
          kubectl patch deployment $DEPLOYMENT -n $NAMESPACE --patch "
          spec:
            template:
              spec:
                volumes:
                - name: keystore-vol
                  secret:
                    secretName: ballerina-integration-secret
                containers:
                - name: $CONTAINER_NAME
                  envFrom:
                  - configMapRef:
                      name: ballerina-values-mock-backends
                  volumeMounts:
                  - name: keystore-vol
                    mountPath: /home/ballerina/bre/security
                    readOnly: true
          "
          
          # Restart to ensure new ConfigMap and Volume mounts are picked up
          kubectl rollout restart deployment/$DEPLOYMENT -n $NAMESPACE
          
          echo "Waiting for successful rollout..."
          kubectl rollout status deployment/$DEPLOYMENT -n $NAMESPACE --timeout=120s