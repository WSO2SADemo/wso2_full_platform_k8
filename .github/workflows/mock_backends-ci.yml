name: Integration - Mock Backends

on:
  push:
    paths:
      - 'apim-integration-artefacts-for-cicd-pipeline/integration/integrations-2/mock_backends/**'
      - '.github/workflows/mock_backends-ci.yml'
    branches:
      - main
  
  # Allows manual triggering from GitHub Actions UI
  workflow_dispatch:

jobs:
  build-and-deploy:
    runs-on: self-hosted

    env:
      BALLERINA_NAMESPACE: ballerina 
      PROJECT_DIR: apim-integration-artefacts-for-cicd-pipeline/integration/integrations-2/mock_backends
      IMAGE_TAG: "1.0.9"
      MOESIF_APP_ID: "eyJhcHAiOiI0OTM6MzM3MiIsInZlciI6IjIuMSIsIm9yZyI6Ijg2OjcxMiIsImlhdCI6MTc2NzIyNTYwMH0.XD0ilo6xwD8igZvVaQgz4w9kIvyx_yMTBbrBWdZyEVs" # ‚ö†Ô∏è Replace this!

    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Print Ballerina Version
        run: bal version

      - name: Build Ballerina Project
        working-directory: ${{ env.PROJECT_DIR }}
        run: bal build
      
      - name: üîê Docker Login
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
          
      - name: Retag and Push Docker Image
        run: |
          # 1. Find the most recently built image
          BUILT_IMAGE=$(docker images --format "{{.Repository}}:{{.Tag}}" | grep "ramilu90/mock_backend" | head -n 1)
          
          if [ -z "$BUILT_IMAGE" ]; then
            echo "Error: No image found matching 'ramilu90/mock_backend'"
            exit 1
          fi
          
          echo "Found built image: $BUILT_IMAGE"
          
          # 2. Retag explicitly
          TARGET_IMAGE="ramilu90/mock_backend:${{ env.IMAGE_TAG }}"
          docker tag "$BUILT_IMAGE" "$TARGET_IMAGE"
          
          # 3. Push
          docker push "$TARGET_IMAGE"

      - name: Ensure Namespace Exists
        run: kubectl create namespace ${{ env.BALLERINA_NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -

      # -----------------------------------------------------------
      # üì¶ 1. Create Logging ConfigMaps (FluentBit + OTEL)
      # -----------------------------------------------------------
      - name: Create Logging ConfigMaps
        run: |
          NAMESPACE="${{ env.BALLERINA_NAMESPACE }}"

          # --- OTEL Collector Config ---
          cat <<EOF > otelcol.yaml
          receivers:
            otlp:
              protocols:
                http:
                  endpoint: "0.0.0.0:4318"
          processors:
            resource:
              attributes:
              - key: service.name
                value: mock-backends
                action: upsert
            batch: {}
          exporters:
            otlphttp:
              endpoint: "https://api.moesif.net"
              logs_endpoint: "https://api.moesif.net/v1/logs"
              headers:
                X-Moesif-Application-Id: "${{ env.MOESIF_APP_ID }}"
          service:
            pipelines:
              logs:
                receivers: [otlp]
                processors: [resource, batch]
                exporters: [otlphttp]
          EOF

          # --- Fluent Bit Config ---
          cat <<EOF > fluent-bit.conf
          [SERVICE]
              Flush        1
              Daemon       off
              Log_Level    info
              Parsers_File parsers.conf

          [INPUT]
              Name             tail
              Path             /home/ballerina/logs/app.log
              Tag              bi.*
              Read_from_Head   true
              Mem_Buf_Limit    5MB

          [OUTPUT]
              Name             opentelemetry
              Match            bi.*
              Host             localhost
              Port             4318
              Logs_uri         /v1/logs
              Log_response_payload True
              Tls              Off
          EOF

          # Apply Logging ConfigMaps
          echo "Applying Logging ConfigMaps..."
          kubectl create configmap otel-config --from-file=otelcol.yaml -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
          kubectl create configmap fluentbit-config --from-file=fluent-bit.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

      # -----------------------------------------------------------
      # ‚öôÔ∏è 2. Create Main Ballerina ConfigMap
      # -----------------------------------------------------------
      - name: Create Ballerina ConfigMap
        run: |
          NAMESPACE="${{ env.BALLERINA_NAMESPACE }}"
          
          # We use cat <<EOF to handle newlines correctly. 
          cat <<EOF > configmap.yaml
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: ballerina-values-mock-backends
            namespace: $NAMESPACE
          data:
            BAL_CONFIG_VAR_BALLERINAX_WSO2_CONTROLPLANE_NODEID: "mock_backends"
            BAL_CONFIG_DATA: |
              # --- Observability (Moesif) ---
              [ballerina.observe]
              tracingEnabled=true
              tracingProvider="moesif"
              metricsEnabled=true
              metricsReporter="moesif"

              [ballerinax.moesif]
              applicationId = "${{ env.MOESIF_APP_ID }}"
              
              # --- Logging to File (For FluentBit) ---
              [ballerina.log]
              format = "json"
              [[ballerina.log.destinations]]
              path = "/home/ballerina/logs/app.log"

              # --- WSO2 Integration Control Plane ---
              [ballerinax.wso2.controlplane.dashboard]
              url="https://cloud-icp.icp.svc.cluster.local:9743/dashboard/api"
              heartbeatInterval=10
              groupId="cluster1"
              mgtApiUrl="https://mock-backends.ballerina.svc.cluster.local:9264/management/"
              nodeId="mock_backends"

              # --- APIM Service Catalog ---
              [ballerinax.wso2.apim.catalog]
              serviceUrl="https://acp-wso2am-acp-service.apim-cp.svc.cluster.local:9443/api/am/service-catalog/v1"
              tokenUrl="https://acp-wso2am-acp-service.apim-cp.svc.cluster.local:9443/oauth2/token"
              username="admin"
              password="admin"
              clientId="<clientId>"
              clientSecret="<Client secret>"
          EOF

          echo "Applying Ballerina ConfigMap..."
          kubectl apply -f configmap.yaml

      - name: Deploy Kubernetes Resources
        run: |
          K8S_DIR="${{ env.PROJECT_DIR }}/target/kubernetes/mock_backends"
          echo "Applying resources to Local Cluster..."
          kubectl apply -f ${K8S_DIR} -n ${{ env.BALLERINA_NAMESPACE }}

      # -----------------------------------------------------------
      # üõ† 3. Ensure Service & Patch Ports (Handles Unnamed Ports)
      # -----------------------------------------------------------
      - name: Ensure Service & Patch Ports
        run: |
          NAMESPACE="${{ env.BALLERINA_NAMESPACE }}"
          DEPLOYMENT="mock-backends-deployment"
          SERVICE_NAME="mock-backends" 

          # A. Create Service if missing
          if ! kubectl get svc $SERVICE_NAME -n $NAMESPACE > /dev/null 2>&1; then
             echo "Service not found. Creating it now..."
             # We create it with a NAME immediately
             kubectl expose deployment $DEPLOYMENT -n $NAMESPACE --name=$SERVICE_NAME --port=9092 --target-port=9092 --type=ClusterIP --name=serviceport
          else
             echo "Service $SERVICE_NAME already exists."
          fi

          # B. Ensure existing port (Index 0) has a name
          # Kubernetes requires ALL ports to be named if >1 port exists.
          EXISTING_PORT_NAME=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.ports[0].name}')
          
          if [ -z "$EXISTING_PORT_NAME" ]; then
             echo "Port 9092 is unnamed. Adding name 'serviceport'..."
             kubectl patch svc $SERVICE_NAME -n $NAMESPACE --type='json' -p='[{"op": "add", "path": "/spec/ports/0/name", "value": "serviceport"}]'
          else
             echo "Existing port already has name: $EXISTING_PORT_NAME"
          fi

          # C. Add 'management' port (9264)
          if kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.ports[*].port}' | grep -q "9264"; then
             echo "Port 9264 already exists. Skipping patch."
          else
             echo "Adding 'management' port 9264..."
             kubectl patch svc $SERVICE_NAME -n $NAMESPACE --type='json' -p='[{"op": "add", "path": "/spec/ports/-", "value": {"name": "management", "port": 9264, "targetPort": 9264, "protocol": "TCP"}}]'
          fi

      # -----------------------------------------------------------
      # üè• 4. Patch Deployment (Sidecars + Volumes)
      # -----------------------------------------------------------
      - name: Patch Deployment (Sidecars & Volumes)
        run: |
          NAMESPACE="${{ env.BALLERINA_NAMESPACE }}"
          DEPLOYMENT="mock-backends-deployment"
          CONTAINER_NAME=$(kubectl get deployment $DEPLOYMENT -n $NAMESPACE -o jsonpath='{.spec.template.spec.containers[0].name}')
          
          # Create Patch File
          cat <<EOF > deployment-patch.yaml
          spec:
            template:
              spec:
                volumes:
                - name: keystore-vol
                  secret:
                    secretName: ballerina-integration-secret
                - name: log-volume
                  emptyDir: {}
                - name: otel-config-vol
                  configMap:
                    name: otel-config
                - name: fluentbit-config-vol
                  configMap:
                    name: fluentbit-config
                containers:
                # --- Main Ballerina App ---
                - name: $CONTAINER_NAME
                  envFrom:
                  - configMapRef:
                      name: ballerina-values-mock-backends
                  volumeMounts:
                  - name: keystore-vol
                    mountPath: /home/ballerina/bre/security
                    readOnly: true
                  - name: log-volume
                    mountPath: /home/ballerina/logs
                
                # --- OTEL Sidecar ---
                - name: otel-collector
                  image: otel/opentelemetry-collector-contrib:0.119.0
                  args: ["--config=/etc/otelcol.yaml"]
                  volumeMounts:
                  - name: otel-config-vol
                    mountPath: /etc/otelcol.yaml
                    subPath: otelcol.yaml

                # --- Fluent Bit Sidecar ---
                - name: fluent-bit
                  image: fluent/fluent-bit:3.2
                  volumeMounts:
                  - name: fluentbit-config-vol
                    mountPath: /fluent-bit/etc/fluent-bit.conf
                    subPath: fluent-bit.conf
                  - name: log-volume
                    mountPath: /app/logs
                    readOnly: true
          EOF

          echo "Applying Deployment Patch..."
          kubectl patch deployment $DEPLOYMENT -n $NAMESPACE --patch-file deployment-patch.yaml
          
          # Force Restart
          kubectl rollout restart deployment/$DEPLOYMENT -n $NAMESPACE
          
          echo "Waiting for rollout..."
          kubectl rollout status deployment/$DEPLOYMENT -n $NAMESPACE --timeout=120s