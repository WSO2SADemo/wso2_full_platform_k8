name: Integration - Ochastration and Email/SMS

on:
  push:
    paths:
      - 'apim-integration-artefacts-for-cicd-pipeline/integration/integrations-2/orchestration_and_email_sms/**'
      - '.github/workflows/ochestration_email_sms-ci.yml'
    branches:
      - main
  
  # Allows manual triggering
  workflow_dispatch:

jobs:
  build-and-deploy:
    runs-on: self-hosted

    env:
      BALLERINA_NAMESPACE: ballerina 
      PROJECT_DIR: apim-integration-artefacts-for-cicd-pipeline/integration/integrations-2/orchestration_and_email_sms
      IMAGE_TAG: "1.0.5"
      MOESIF_APP_ID: "eyJhcHAiOiI0OTM6MzM3MiIsInZlciI6IjIuMSIsIm9yZyI6Ijg2OjcxMiIsImlhdCI6MTc2NzIyNTYwMH0.XD0ilo6xwD8igZvVaQgz4w9kIvyx_yMTBbrBWdZyEVs" 

    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Print Ballerina Version
        run: bal version

      - name: Build Ballerina Project
        working-directory: ${{ env.PROJECT_DIR }}
        run: bal build
      
      - name: üîê Docker Login
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
          
      - name: Retag and Push Docker Image
        run: |
          # 1. Find the image ID built by Ballerina (uses the most recent one)
          BUILT_IMAGE=$(docker images --format "{{.Repository}}:{{.Tag}}" | grep "ramilu90/orchestration_and_email_sms" | head -n 1)
          
          if [ -z "$BUILT_IMAGE" ]; then
            echo "Error: No image found matching 'ramilu90/orchestration_and_email_sms'"
            exit 1
          fi
          
          echo "Found built image: $BUILT_IMAGE"
          
          # 2. Retag explicitly to match your deployment requirements
          TARGET_IMAGE="ramilu90/orchestration_and_email_sms:${{ env.IMAGE_TAG }}"
          docker tag "$BUILT_IMAGE" "$TARGET_IMAGE"
          
          # 3. Push
          docker push "$TARGET_IMAGE"

      - name: Ensure Namespace Exists
        run: kubectl create namespace ${{ env.BALLERINA_NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -

      # -----------------------------------------------------------
      # ‚úÖ FIX 1: ConfigMap with CORRECT formatting (using | )
      # -----------------------------------------------------------
      - name: Create ConfigMap
        run: |
          NAMESPACE="${{ env.BALLERINA_NAMESPACE }}"
          
          # We use cat <<EOF to handle newlines correctly. 
          cat <<EOF > configmap.yaml
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: ballerina-values-ochastration-and-email-sms
            namespace: $NAMESPACE
          data:
            BAL_CONFIG_DATA: |
              # [ballerinax.wso2.controlplane.dashboard]
              # url="https://cloud-icp.icp.svc.cluster.local:9743/dashboard/api"
              # heartbeatInterval=10
              # groupId="cluster1"
              # mgtApiUrl="https://mock-backends.ballerina.svc.cluster.local:9264/management/"
              # nodeId="orchestration_and_email_sms"

              [ballerina.observe]
              tracingEnabled=true
              tracingProvider="moesif"
              metricsEnabled=true
              metricsReporter="moesif"

              [ballerinax.moesif]
              applicationId = "eyJhcHAiOiI0OTM6MzM3MiIsInZlciI6IjIuMSIsIm9yZyI6Ijg2OjcxMiIsImlhdCI6MTc2NzIyNTYwMH0.XD0ilo6xwD8igZvVaQgz4w9kIvyx_yMTBbrBWdZyEVs"
              reporterBaseUrl = "https://api.moesif.net"   
              tracingReporterFlushInterval = 1000         
              tracingReporterBufferSize = 10000            
              isTraceLoggingEnabled = true                
              isPayloadLoggingEnabled = false 
              
              # # --- Logging to File (For FluentBit) ---
              # [ballerina.log]
              # format = "json"
              # [[ballerina.log.destinations]]
              # path = "/home/ballerina/logs/app.log"

              # [[ballerina.log.destinations]]
              # path = "/home/ballerina/logs/app.log"

              [ballerinax.wso2.apim.catalog]
              serviceUrl="https://acp-wso2am-acp-service.apim-cp.svc.cluster.local:9443/api/am/service-catalog/v1"
              tokenUrl="https://acp-wso2am-acp-service.apim-cp.svc.cluster.local:9443/oauth2/token"
              username="admin"
              password="admin"
              clientId="Pvn5k2ijIq04b1JzbPaSFJbyIfIa"
              clientSecret="y7gXcCrf9HJrBWTR5F0MbH6qpzQa"
          EOF

          echo "Applying Corrected ConfigMap..."
          kubectl apply -f configmap.yaml

      - name: Deploy Kubernetes Resources
        run: |
          K8S_DIR="${{ env.PROJECT_DIR }}/target/kubernetes/orchestration_and_email_sms"
          echo "Applying resources to Local Cluster..."
          kubectl apply -f ${K8S_DIR} -n ${{ env.BALLERINA_NAMESPACE }}

      # -----------------------------------------------------------
      # ‚úÖ FIX 2: Robust Service Patching (Handles Unnamed Ports)
      # -----------------------------------------------------------
      - name: Ensure Service & Patch Ports (Orchestration)
        run: |
          NAMESPACE="${{ env.BALLERINA_NAMESPACE }}"
          DEPLOYMENT="orchestration-a-deployment"
          SERVICE_NAME="orchestration"
          
          # Define prefixed port names
          MAIN_PORT_NAME="${SERVICE_NAME}-serviceport"
          MGT_PORT_NAME="${SERVICE_NAME}-management"

          # 1. Create Service if missing
          if ! kubectl get svc $SERVICE_NAME -n $NAMESPACE > /dev/null 2>&1; then
             echo "Service not found. Creating it now..."
             kubectl expose deployment $DEPLOYMENT -n $NAMESPACE --name=$SERVICE_NAME --port=9090 --target-port=9090 --type=ClusterIP
          else
             echo "Service $SERVICE_NAME already exists."
          fi

          # 2. PATCH: Rename Main Port (Index 0)
          # We check if the CURRENT name matches the DESIRED name.
          EXISTING_MAIN_NAME=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.ports[0].name}')
          
          if [ "$EXISTING_MAIN_NAME" != "$MAIN_PORT_NAME" ]; then
             echo "Updating port 0 name from '$EXISTING_MAIN_NAME' to '$MAIN_PORT_NAME'..."
             
             # If name is empty, we 'add'. If it exists (e.g. 'serviceport'), we 'replace'.
             if [ -z "$EXISTING_MAIN_NAME" ]; then OP="add"; else OP="replace"; fi
             
             kubectl patch svc $SERVICE_NAME -n $NAMESPACE --type='json' -p='[{"op": "'$OP'", "path": "/spec/ports/0/name", "value": "'"$MAIN_PORT_NAME"'"}]'
          else
             echo "Main port is already correctly named: $EXISTING_MAIN_NAME"
          fi

          # 3. PATCH: Handle Management Port (9264)
          # First, check if port 9264 exists.
          if kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.ports[*].port}' | grep -q "9264"; then
             # It exists. Now check if it is named correctly (assuming it is at Index 1)
             EXISTING_MGT_NAME=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.ports[1].name}')
             
             if [ "$EXISTING_MGT_NAME" != "$MGT_PORT_NAME" ]; then
                 echo "Updating port 1 name from '$EXISTING_MGT_NAME' to '$MGT_PORT_NAME'..."
                 if [ -z "$EXISTING_MGT_NAME" ]; then OP="add"; else OP="replace"; fi
                 kubectl patch svc $SERVICE_NAME -n $NAMESPACE --type='json' -p='[{"op": "'$OP'", "path": "/spec/ports/1/name", "value": "'"$MGT_PORT_NAME"'"}]'
             else
                 echo "Management port is already correctly named: $EXISTING_MGT_NAME"
             fi
          else
             echo "Management port missing. Adding '$MGT_PORT_NAME'..."
             kubectl patch svc $SERVICE_NAME -n $NAMESPACE --type='json' -p='[{"op": "add", "path": "/spec/ports/-", "value": {"name": "'"$MGT_PORT_NAME"'", "port": 9264, "targetPort": 9264, "protocol": "TCP"}}]'
          fi

      - name: Patch Deployment (Volume Mounts & Env)
        run: |
          NAMESPACE="${{ env.BALLERINA_NAMESPACE }}"
          DEPLOYMENT="mock-backends-deployment"
          
          # Note: We do NOT wait for rollout here because if the pod is crashing, 
          # the rollout hangs and fails. We patch immediately to fix the crash.
          
          CONTAINER_NAME=$(kubectl get deployment $DEPLOYMENT -n $NAMESPACE -o jsonpath='{.spec.template.spec.containers[0].name}')
          
          echo "Patching Deployment $DEPLOYMENT (Container: $CONTAINER_NAME)..."
          
          kubectl patch deployment $DEPLOYMENT -n $NAMESPACE --patch "
          spec:
            template:
              spec:
                volumes:
                - name: keystore-vol
                  secret:
                    secretName: ballerina-integration-secret
                containers:
                - name: $CONTAINER_NAME
                  envFrom:
                  - configMapRef:
                      name: ballerina-values-mock-backends
                  volumeMounts:
                  - name: keystore-vol
                    mountPath: /home/ballerina/bre/security
                    readOnly: true
          "
          
          # Restart to ensure new ConfigMap and Volume mounts are picked up
          kubectl rollout restart deployment/$DEPLOYMENT -n $NAMESPACE
          
          echo "Waiting for successful rollout..."
          kubectl rollout status deployment/$DEPLOYMENT -n $NAMESPACE --timeout=120s